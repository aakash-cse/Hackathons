{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error of is 487.79525007054207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Hypertuning the Random Forest Regressor\\n\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\nparams={\\n        \"n_estimators\":[50,100,150,200],\\n        \"criterion\":[\\'mse\\',\\'mae\\'],\\n        \"max_depth\":[10,20,30],\\n        \"max_features\":[\"auto\", \"sqrt\", \"log2\"]        \\n        }\\n\\nrandom = RandomizedSearchCV(cls,params,random_state=0,n_jobs=-1,verbose=1)\\nrandom.fit(X_train,y_train)\\n\\nprint(random.best_params_)\\nprint(random.best_estimator_)\\n\\n\\n# Convert the submission file for submission\\nsub = cls.predict(test)\\nsubmission = pd.DataFrame()\\nsubmission[\\'tumor_size\\'] = sub\\nsubmission.to_csv(\"Submission-extratree.csv\",index=False)\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Aug  8 20:00:15 2020\n",
    "\n",
    "@author: Aakash Babu\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_input():\n",
    "    train = pd.read_csv(\"Train.csv\")\n",
    "    test = pd.read_csv(\"Test.csv\")\n",
    "    return train,test\n",
    "\n",
    "train,test = get_input()\n",
    "\n",
    "#--------------Printing for the null values in the train ---------#\n",
    "\n",
    "def null_value():\n",
    "    print(train.isnull().sum())\n",
    "    print(test.isnull().sum())\n",
    "\n",
    "#   null_value()\n",
    "\n",
    "# ------- So there is no null values so we can proceed to the next steps\n",
    "\n",
    "'''\n",
    "In this problem it is nothing but the Supervised(Regression) problem \n",
    "\n",
    "where the target variable in tumor_size \n",
    "\n",
    "'''\n",
    "# ------ let us find what are the qualitative and quanditative values\n",
    "\n",
    "def print_unique():\n",
    "    for val in train.columns:\n",
    "        print(\"The column {} is {}\".format(val,len(train[val].unique())))\n",
    "        \n",
    "#  print_unique()\n",
    "\n",
    "# ------ from this we come to know that these features are quanditative ---------#\n",
    "\n",
    "'''\n",
    "Let us discuss the features and uses\n",
    "\n",
    "mass_npea:  the mass of the area understudy for melanoma tumor\n",
    "size_npear: the size of the area understudy for melanoma tumor\n",
    "malign_ratio: ration of normal to malign surface understudy\n",
    "damage_size: unrecoverable area of skin damaged by the tumor\n",
    "exposed_area: total area exposed to the tumor\n",
    "std_dev_malign: standard deviation of malign skin measurements\n",
    "err_malign: error in malign skin measurements\n",
    "malign_penalty: penalty applied due to measurement error in the lab\n",
    "damage_ratio: the ratio of damage to total spread on the skin\n",
    "tumor_size: size of melanoma_tumor\n",
    "\n",
    "'''\n",
    "\n",
    "# This problem doesn't include good feature engineering since it doesn't have any null values\n",
    "\n",
    "X = train.drop(['tumor_size'],axis=1)\n",
    "y = train['tumor_size']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0,test_size=0.33)\n",
    "\n",
    "'''\n",
    "# Decision tree Regressor for regression\n",
    "\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "\n",
    "cls = ExtraTreeRegressor()\n",
    "cls.fit(X_train,y_train)\n",
    "\n",
    "pred = cls.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"The mean squared error is {}\".format(mean_squared_error(pred,y_test)))\n",
    "\n",
    "# output The mean squared error is 34.18461074039417\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(y_test-pred)\n",
    "\n",
    "\n",
    "RandomForestRegressor()\n",
    "The mean squared error is 16.776179302803882\n",
    "\n",
    "After hypter tuning\n",
    "RandomForestRegressor(max_depth=30, max_features='log2', n_estimators=150)\n",
    "\n",
    "The mean squared error is 16.553698616492934\n",
    "\n",
    "ExtraTreesRegressor\n",
    "\n",
    "The mean squared error is 15.65352146904475\n",
    "'''\n",
    "\n",
    "# Random Forest Regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "#cls = ExtraTreesRegressor(n_estimators=150,max_depth=30,random_state=0)\n",
    "cls = CatBoostRegressor()\n",
    "cls.fit(X_train,y_train)\n",
    "\n",
    "pred = cls.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"The mean squared error of is {}\".format(mean_squared_error(pred,y_test)))\n",
    "\n",
    "\n",
    "'''\n",
    "# Hypertuning the Random Forest Regressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params={\n",
    "        \"n_estimators\":[50,100,150,200],\n",
    "        \"criterion\":['mse','mae'],\n",
    "        \"max_depth\":[10,20,30],\n",
    "        \"max_features\":[\"auto\", \"sqrt\", \"log2\"]        \n",
    "        }\n",
    "\n",
    "random = RandomizedSearchCV(cls,params,random_state=0,n_jobs=-1,verbose=1)\n",
    "random.fit(X_train,y_train)\n",
    "\n",
    "print(random.best_params_)\n",
    "print(random.best_estimator_)\n",
    "\n",
    "\n",
    "# Convert the submission file for submission\n",
    "sub = cls.predict(test)\n",
    "submission = pd.DataFrame()\n",
    "submission['tumor_size'] = sub\n",
    "submission.to_csv(\"Submission-extratree.csv\",index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.19.1-cp37-cp37m-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\n",
      "Successfully installed numpy-1.19.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: py-agender 0.0.9 has requirement numpy<=1.15.9,>=1.13, but you'll have numpy 1.19.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aakash Babu\\anaconda3\\envs\\gputensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -27430.14 (8900.11) MSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27439.43084551024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "seed = 1\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n",
    "estimator.fit(X, y)\n",
    "prediction = estimator.predict(X)\n",
    "mean_squared_error(y, prediction)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
